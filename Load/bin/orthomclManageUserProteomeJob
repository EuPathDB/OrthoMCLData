#!/usr/bin/perl

use lib "$ENV{GUS_HOME}/lib/perl";
use File::Path;
use File::Copy;
use GUS::Workflow::SshCluster;
use OrthoMCLData::Load::ProteomeJobMgr;
use strict;

=pod 

probe the state of orthomcl user's proteome analysis jobs

should be called by cron once every few minutes

** local dir structure **
controlDir/
  newJobs/
    92hty2k/
      info.txt
      proteome.fasta
  runningJobs/
    i83j89/
      info.txt
      input/
        controller.prop
        proteome.fasta
        task.prop
  doneJobs/
    43k8sl0/
      blastSimilarity.out
  failedJobs/
    a7bbe32/                (copied from runningJobs/)


** cluster dir structure **
orthomclUserProteomeJobs/
  runningJobs/
    i83j89/
      info.txt
      input/
        proteome.fasta
      master/
        completedSubtasks.log
        failures/
        mainresult/
        running/
      i83j89.log
      processId
  failedJobs/
    i83j89/        (copied from runningJobs/)
    i83j89.log     (copied from runningJobs/)


** info.txt file **
email=
fastaFileName=
submitTime=

=cut

usage() unless scalar(@ARGV) == 1;

my $configFile = $ARGV[0];

my $controlDir;
my $clusterServerDir;

my $mgr = OrthoMCLData::Load::ProteomeJobMgr->new($configFile);

eval {
    $controlDir = $mgr->getConfig('controlDir');
    $clusterServerDir = $mgr->getConfig('clusterServerDir');

    my ($doneJobs, $failedJobs) = checkRunningJobs();

    handleDoneJobs($doneJobs);

    handleFailedJobs($failedJobs);

    handleNewJobs();
};

$mgr->error("error: '$@'") if $@;


##################################################
# handle new jobs
##################################################
sub handleNewJobs {
    my $localRunningDir = "$controlDir/runningJobs";

    # find all subdirs of newJobs/ (put there by front end)
    opendir(DIR, "$controlDir/newJobs") || die "Can't open newJobs/ directory '$controlDir/newJobs'\n";
    my @newJobs = readdir(DIR);
    closedir(DIR);

    foreach my $newJob (@newJobs) {
	next if $newJob =~ /^\./;
	$mgr->log("New job: $newJob");

	my $newJobDir = "$controlDir/newJobs/$newJob";
	my $localRunningDir = "$controlDir/runningJobs";
	my $runningJobDir = "$localRunningDir/$newJob";
	my $localInputDir = "$runningJobDir/input";
	my $masterDir = "$runningJobDir/master";
	my $clusterRunningJobDir = "$clusterServerDir/runningJobs/$newJob";
	my $clusterInputDir = "$clusterRunningJobDir/input";

	validateProteomeFile("$newJobDir/proteome.fasta");

        # move dir from new/ to running/
	mkpath($runningJobDir);
	move("$controlDir/newJobs/$newJob", $runningJobDir);

	# move proteome file to localInputDir
	mkpath($localInputDir);
	move("$runningJobDir/proteome.fasta", $localInputDir);

	# build input/ dir
	makeTaskFile($localInputDir, $clusterInputDir);
	makeControllerFile($localInputDir, $clusterInputDir);

	# mirror job to cluster
	$mgr->log("Mirroring $newJob/ to cluster");
	$mgr->getCluster()->copyTo($localRunningDir, $newJob, "$clusterServerDir/runningJobs");

	# start job
	startJob("$clusterRunningJobDir", $newJob);
    }

}

sub validateProteomeFile {
    my ($proteomeFile) = @_;
}

sub makeTaskFile {
    my ($localInputDir,$clusterInputDir) = @_;
      open(F, ">$localInputDir/task.prop") || die "Can't open task prop file '$localInputDir/task.prop' for writing";

    my $blastBinDir = $mgr->getConfig('blastBinDir');
    my $subjectFile = $mgr->getConfig('subjectFile');
    my $blastArgs = $mgr->getConfig('blastArgs');

    print F
"blastBinDir=$blastBinDir
dbFilePath=$subjectFile
inputFilePath=$clusterInputDir/proteome.fasta
dbType=p
regex='(\S+)'
blastProgram=blastp
blastParamsFile=blastParams
blastVendor=ncbi
";
    close(F);

    # make blastParams file
    open(F, ">$localInputDir/blastParams") || die "Can't open blast params file '$localInputDir/blastParams' for writing";;
    print F "$blastArgs\n";
    close(F);
}

sub makeControllerFile {
    my ($localInputDir, $clusterInputDir) = @_;
  my ($self, $taskInputDir, $slotsPerNode, $taskSize, $taskClass) = @_;

  my $nodePath = $mgr->getConfig('nodePath');
  my $slotsPerNode = $mgr->getConfig('slotsPerNode');
  my $nodeClass = $mgr->getConfig('nodeClass');
  my $taskSize = $mgr->getConfig('taskSize');
  my $taskClass = $mgr->getConfig('taskClass');
  my $nodeClass = $mgr->getConfig('nodeClass');

  my $clusterMasterDir = $clusterInputDir;
  $clusterMasterDir =~ s/input/master/;
  $nodeClass = 'DJob::DistribJob::BprocNode' unless $nodeClass;

  # print out the file
  my $controllerPropFile = "$localInputDir/controller.prop";
  open(F, ">$controllerPropFile")
      || $self->error("Can't open controller prop file '$controllerPropFile' for writing");
  print F 
"masterdir=$clusterMasterDir
inputdir=$clusterInputDir
nodedir=$nodePath
slotspernode=$slotsPerNode
subtasksize=$taskSize
taskclass=$taskClass
nodeclass=$nodeClass
restart=no
";
    close(F);
}


sub startJob {
    my ($clusterJobDir, $jobName) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $numNodes = $mgr->getConfig('numNodes');
    my $clusterQueue = $mgr->getConfig('clusterQueue');
    my $ppn = $mgr->getConfig('ppn');

    $mgr->log("Starting job on cluster in $clusterJobDir");
    $mgr->runClusterTask($clusterUserName, $clusterServer, "$clusterJobDir/processId", "$clusterJobDir/$jobName.log", "$clusterJobDir/input/controller.prop", $numNodes, 14400, $clusterQueue, $ppn);
}


##################################################
# handle running jobs
##################################################

sub checkRunningJobs {

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');

    mkpath("$controlDir/runningJobs");
    opendir(DIR, "$controlDir/runningJobs") || die "Can't open runningJobs/ directory '$controlDir/runningJobs'\n";
    my @runningJobs = readdir(DIR);
    closedir(DIR);

    my $doneJobs;
    my $failedJobs;
    foreach my $runningJob (@runningJobs) {
	next if $runningJob =~ /^\./;
	print STDERR "checking for done: $runningJob\n";
	my $clusterRunningJobDir = "$clusterServerDir/runningJobs/$runningJob";
	if (!clusterTaskRunning($clusterRunningJobDir, $clusterUserName, $clusterServer)) {
	  $mgr->log("Found job that has finished running: $runningJob");
	  my $logFile = "$clusterRunningJobDir/$runningJob.log";
	  my $done = $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"if [ -a $logFile ]; then tail -1 $logFile; fi\"'");
	  if ($done && $done =~ /Done/) {
	    push(@$doneJobs, $runningJob);
	  } else {
	    push(@$failedJobs, $runningJob);
	  }
	}
      }

    return ($doneJobs, $failedJobs);
}

sub clusterTaskRunning {
    my ($clusterJobDir, $clusterUserName, $clusterServer) = @_;

    my $processId = `ssh -2 $clusterUserName\@$clusterServer 'if [ -a $clusterJobDir/processId ];then cat $clusterJobDir/processId; fi'`;

    chomp $processId;

    my $status = 0;
    if ($processId) {
      system("ssh -2 $clusterUserName\@$clusterServer 'ps -p $processId > /dev/null'");
      $status = $? >> 8;
      $status = !$status;
    }
    return $status;
}


##################################################
# handle completed jobs
##################################################
sub handleDoneJobs {
    my ($doneJobs) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $groupsFile = $mgr->getConfig('groupsFile');
    my $localRunningDir = "$controlDir/runningJobs";
    my $localDoneDir = "$controlDir/doneJobs";

    foreach my $doneJob (@$doneJobs) {

      $mgr->log("Handling done job: $doneJob");
      mkpath($localDoneDir);
      move("$localRunningDir/$doneJob", "$localDoneDir/$doneJob");

      # copy result from cluster
      $mgr->log("  copying from cluster");
      my $clusterRunningJobDir = "$clusterServerDir/runningJobs/$doneJob";
      $mgr->getCluster()->copyFrom("$clusterRunningJobDir/master/mainresult", 'blastSimilarity.out', "$localDoneDir/$doneJob");

      # map to groups
      $mgr->log("  mapping to groups");
      $mgr->runCmd(0, "orthomclMapProteomeToGroups $localDoneDir/$doneJob/blastSimilarity.out $groupsFile >> $localDoneDir/$doneJob/result");

      # zip result
      $mgr->log("  zipping");
      $mgr->runCmd(0, "zip $localDoneDir/$doneJob/result.zip $localDoneDir/$doneJob/result");
      $mgr->runCmd(0, "rm $localDoneDir/$doneJob/result");

      # clean up cluster dir
      $mgr->log("  cleaning up cluster job dir");
      my $done = $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"rm -rf $clusterRunningJobDir\"'");

      # email result

      # clean up local dir
      $mgr->log("  cleaning up local job dir");
      #remove("$localRunningDir/$doneJob");
    }
  }

##################################################
# handle failed jobs
##################################################
sub handleFailedJobs {
    my ($failedJobs) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $localRunningDir = "$controlDir/runningJobs";
    my $localFailedDir = "$controlDir/failedJobs";

    foreach my $failedJob (@$failedJobs) {

      $mgr->log("Handling failed job: $failedJob");
      mkpath("$localRunningDir/$failedJob");
      move("$localRunningDir/$failedJob", "$localFailedDir/$failedJob");

      # clean up cluster dir
      $mgr->log("  moving cluster job to failed dir");
      my $clusterRunningJobDir = "$clusterServerDir/runningJobs/$failedJob";
      my $done = $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"mv $clusterRunningJobDir $clusterServerDir/failedJobs\"'");
    }
}

sub usage {
  print STDERR "

usage:
   orthomclManageUserProteomeJob config_file

** config file **
controlDir=           (local dir to control this job)
clusterUserName=      (login to use to get into cluster server)
clusterServer=        (name of machine)
clusterServerDir=     (dir there to put our stuff in)
clusterQueue=         (queue to use)
numNodes=             (num of nodes to request)
slotsPerNode=         (slots per each node)
ppn=                  (parallelization)
nodePath=             (???)
nodeClass=            (perl class to represent this type of node)
taskSize=             (number of seqs to process in one batch)
taskClass=            (perl class to manage that processing)
subjectFile=          (blast database file)
blastArgs=            (arguments for blast)
blastBinDir=          (location of blast executable)
groupsFile=           (orthomcl groups to map blast results to)
";

exit(1);

}


