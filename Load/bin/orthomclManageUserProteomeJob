#!/usr/bin/perl

use lib "$ENV{GUS_HOME}/lib/perl";
use File::Path;
use File::Copy;
use GUS::Workflow::SshCluster;
use OrthoMCLData::Load::ProteomeJobMgr
use strict;

=pod 

probe the state of orthomcl user's proteome analysis jobs

should be called by cron once every few minutes

** config file **
controlDir=           (local dir to control this job)
clusterUserName=      (login to use to get into cluster server)
clusterServer=        (name of machine)   
clusterServerDir=     (dir there to put our stuff in)
clusterQueue=         (queue to use)
numNodes=             (num of nodes to request)
slotsPerNode=         (slots per each node)
ppn=                  (parallelization)
nodePath=             (???)
nodeClass=            (perl class to represent this type of node)
taskSize=             (number of seqs to process in one batch)
taskClass=            (perl class to manage that processing)
subjectFile=          (blast database file)
blastArgs=            (arguments for blast)
blastBinDir=          (location of blast executable)
groupsFile=           (orthomcl groups to map blast results to)


** local dir structure **
controlDir/
  newJobs/
    92hty2k/
      info.txt
      proteome.fasta
  runningJobs/
    i83j89/
      info.txt
      input/
        controller.prop
        proteome.fasta
        task.prop
      master/
      
      
** cluster dir structure **
orthomclUserProteomeJobs
  i83j89/
    info.txt
    input/
    log
    master/   
    processId 
    proteome.fasta


** info.txt file **
email=
fastaFileName=
submitTime=

=cut

usage() unless scalar(@ARGV) == 1;

my $configFile = $ARGV[0];

eval {
    my $mgr = OrthoMCLData::Load:ProteomeJobMgr->new($configFile);
    handleNewJobs();

    my $doneJobs = checkRunningJobs();

    handleCompletedJobs($doneJobs);
}

##################################################
# handle new jobs 
##################################################
sub handleNewJobs {
    my $controlDir = $mgr->getConfig('controlDir');

    # find all subdirs of newJobs/ (put there by front end)
    opendir(DIR, "$controlDir/newJobs") || die "Can't open newJobs/ directory '$controlDir/newJobs'\n";
    my @newJobs = readdir(DIR);
    closedir(DIR);

    foreach my $newJob (@newJobs) {
	next if $newJob =~ /^\./;
	my $newJobDir = "$controlDir/newJobs/$newJob";

	validateProteomeFile("$newJobDir/proteome.fasta");

       # move dir from new/ to running/
	mkpath("$controlDir/runningJobs");
	my $localRunningDir = "$controlDir/runningJobs"
	move("$controlDir/newJobs/$newJob", $runDir);

	# move proteome file to localInputDir
	my $localInputDir = "$localRunningDir/$newJob/input";
	move("$newJobDir/proteome.fasta", $localInputDir);

	# build master/ dir
	my $masterDir = "$localRunningDir/master";
	mkpath($masterDir);

	# build input/ dir
	mkpath($localInputDir);
	my $clusterRunningDir = $mgr->getConfig('clusterServerDir');
	my $clusterInputDir = "$clusterRunningDir/$newJob/input";
	makeTaskFile($localInputDir, $clusterInputDir);
	makeControllerFile($localInputDir, $clusterInputDir);

	# mirror job to cluster
	mirrorToCluster($localRunningDir, $newJob, $clusterRunningDir);

	# start job
	startJob("$clusterRunningDir/$newJob");
    }

}

sub validateProteomeFile {
    my ($proteomeFile) = @_;
}

sub makeTaskFile {
    my ($localInputDir,$clusterInputDir) = @_;
      open(F, ">$localInputDir/task.prop") || die "Can't open task prop file '$inputDir/task.prop' for writing";

    my $blastPath = $mgr->getConfig('blastPath');
    my $subjectFile = $mgr->getConfig('subjectFile');

    print F
"blastBinDir=$blastPath
dbFilePath=$subjectFile
inputFilePath=$clusterInputDir/proteome.fasta
dbType=p
regex='$idRegex'
blastProgram=blastp
blastParamsFile=blastParams
";
    close(F);

    # make blastParams file
    open(F, ">$localInputDir/blastParams") || die "Can't open blast params file '$localBlastParamsFile' for writing";;
    print F "$blastArgs\n";
    close(F);
}

sub makeControllerFile {
    my ($localInputDir, $clusterInputDir) = @_;
  my ($self, $taskInputDir, $slotsPerNode, $taskSize, $taskClass) = @_;

  my $nodePath = $mgr->getConfig('nodePath');
  my $slotsPerNode = $mgr->getConfig('slotsPerNode');
  my $nodeClass = $mgr->getConfig('nodeClass');
  my $taskSize = $mgr->getConfig('taskSize');
  my $taskClass = $mgr->getConfig('taskClass');
  my $nodeClass = $mgr->getConfig('nodeClass');

  my $clusterMasterDir = $clusterInputDir;
  $clusterMasterDir =~ s/input/master/;
  $nodeClass = 'DJob::DistribJob::BprocNode' unless $nodeClass;

  # print out the file
  my $controllerPropFile = "$localInputDir/controller.prop";
  open(F, ">$controllerPropFile")
      || $self->error("Can't open controller prop file '$controllerPropFile' for writing");
  print F 
"masterdir=$clusterMasterDir
inputdir=$clusterInputDir
nodedir=$nodePath
slotspernode=$slotsPerNode
subtasksize=$taskSize
taskclass=$taskClass
nodeclass=$nodeClass
restart=no
";
    close(F);
}

sub mirrorToCluster {
    my ($fromDir, $fromFile, $toDir) = @_;
    $mgr->getCluster()->copyTo($fromDir, $fromFile, $toDir); 
}

sub startJob {
    my ($clusterJobDir) = @_;

    my $clusterUser = $mgr->getConfig('clusterUser');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $numNodes = $mgr->getConfig('numNodes');
    my $clusterQueue = $mgr->getConfig('clusterQueue');
    my $ppn = $mgr->getConfig('ppn');
    
    $mgr->runClusterTask($clusterUser, $clusterServer, "$clusterJobDir/processId", "$clusterJobDir/log", "$clusterJobDir/input/controller.prop", $numNodes, 1400, $clusterQueue, $ppn);
}


##################################################
# handle running jobs
##################################################

# check process id of workflowclusterjob on cluster, based on processId file

# if failed, notify user and admin

# if done, handle complted job


##################################################
# handle completed jobs
##################################################

# copy result from cluster

# map to groups

# deliver result

# clean up cluster server


