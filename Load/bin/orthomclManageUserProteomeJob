#!/usr/bin/perl

use lib "$ENV{GUS_HOME}/lib/perl";
use File::Path;
use File::Copy;
use GUS::Workflow::SshCluster;
use OrthoMCLData::Load::ProteomeJobMgr;
use strict;

=pod 

probe the state of orthomcl user's proteome analysis jobs

should be called by cron once every few minutes

** local dir structure **
controlDir/
  newJobs/
    92hty2k/
      info.txt
      proteome.fasta
  runningJobs/
    i83j89/
      info.txt
      input/
        controller.prop
        proteome.fasta
        task.prop
      master/


** cluster dir structure **
orthomclUserProteomeJobs/
  i83j89/
    info.txt
    input/
      proteome.fasta
    master/
      log
    processId


** info.txt file **
email=
fastaFileName=
submitTime=

=cut

usage() unless scalar(@ARGV) == 1;

my $configFile = $ARGV[0];

my $controlDir;
my $clusterServerDir;

my $mgr = OrthoMCLData::Load::ProteomeJobMgr->new($configFile);

eval {
    $controlDir = $mgr->getConfig('controlDir');
    $clusterServerDir = $mgr->getConfig('clusterServerDir');

    my ($doneJobs, $failedJobs) = checkRunningJobs();

    handleCompletedJobs($doneJobs);

    handleFailedJobs($failedJobs);

    handleNewJobs();
};

$mgr->error("error: '$@'") if $@;


##################################################
# handle new jobs
##################################################
sub handleNewJobs {
    my $localRunningDir = "$controlDir/runningJobs";

    # find all subdirs of newJobs/ (put there by front end)
    opendir(DIR, "$controlDir/newJobs") || die "Can't open newJobs/ directory '$controlDir/newJobs'\n";
    my @newJobs = readdir(DIR);
    closedir(DIR);

    foreach my $newJob (@newJobs) {
	next if $newJob =~ /^\./;
	$mgr->log("New job: $newJob");

	my $newJobDir = "$controlDir/newJobs/$newJob";
	my $localRunningDir = "$controlDir/runningJobs";
	my $runningJobDir = "$localRunningDir/$newJob";
	my $localInputDir = "$runningJobDir/input";
	my $masterDir = "$runningJobDir/master";
	my $clusterRunningDir = "$clusterServerDir/$newJob";
	my $clusterInputDir = "$clusterRunningDir/input";

	validateProteomeFile("$newJobDir/proteome.fasta");

        # move dir from new/ to running/
	mkpath($runningJobDir);
	move("$controlDir/newJobs/$newJob", $runningJobDir);

	# move proteome file to localInputDir
	mkpath($localInputDir);
	move("$runningJobDir/proteome.fasta", $localInputDir);

	# build input/ dir
	makeTaskFile($localInputDir, $clusterInputDir);
	makeControllerFile($localInputDir, $clusterInputDir);

	# mirror job to cluster
	$mgr->log("Mirroring $newJob/ to cluster");
	$mgr->getCluster()->copyTo($localRunningDir, $newJob, $clusterServerDir);

	# start job
	startJob("$clusterRunningDir", $newJob);
    }

}

sub validateProteomeFile {
    my ($proteomeFile) = @_;
}

sub makeTaskFile {
    my ($localInputDir,$clusterInputDir) = @_;
      open(F, ">$localInputDir/task.prop") || die "Can't open task prop file '$localInputDir/task.prop' for writing";

    my $blastBinDir = $mgr->getConfig('blastBinDir');
    my $subjectFile = $mgr->getConfig('subjectFile');
    my $blastArgs = $mgr->getConfig('blastArgs');

    print F
"blastBinDir=$blastBinDir
dbFilePath=$subjectFile
inputFilePath=$clusterInputDir/proteome.fasta
dbType=p
regex='(\S+)'
blastProgram=blastp
blastParamsFile=blastParams
blastVendor=ncbi
";
    close(F);

    # make blastParams file
    open(F, ">$localInputDir/blastParams") || die "Can't open blast params file '$localInputDir/blastParams' for writing";;
    print F "$blastArgs\n";
    close(F);
}

sub makeControllerFile {
    my ($localInputDir, $clusterInputDir) = @_;
  my ($self, $taskInputDir, $slotsPerNode, $taskSize, $taskClass) = @_;

  my $nodePath = $mgr->getConfig('nodePath');
  my $slotsPerNode = $mgr->getConfig('slotsPerNode');
  my $nodeClass = $mgr->getConfig('nodeClass');
  my $taskSize = $mgr->getConfig('taskSize');
  my $taskClass = $mgr->getConfig('taskClass');
  my $nodeClass = $mgr->getConfig('nodeClass');

  my $clusterMasterDir = $clusterInputDir;
  $clusterMasterDir =~ s/input/master/;
  $nodeClass = 'DJob::DistribJob::BprocNode' unless $nodeClass;

  # print out the file
  my $controllerPropFile = "$localInputDir/controller.prop";
  open(F, ">$controllerPropFile")
      || $self->error("Can't open controller prop file '$controllerPropFile' for writing");
  print F 
"masterdir=$clusterMasterDir
inputdir=$clusterInputDir
nodedir=$nodePath
slotspernode=$slotsPerNode
subtasksize=$taskSize
taskclass=$taskClass
nodeclass=$nodeClass
restart=no
";
    close(F);
}


sub startJob {
    my ($clusterJobDir, $jobName) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $numNodes = $mgr->getConfig('numNodes');
    my $clusterQueue = $mgr->getConfig('clusterQueue');
    my $ppn = $mgr->getConfig('ppn');

    $mgr->log("Starting cluster job in $clusterJobDir");
    $mgr->runClusterTask($clusterUserName, $clusterServer, "$clusterJobDir/processId", "$clusterJobDir/$jobName.log", "$clusterJobDir/input/controller.prop", $numNodes, 14400, $clusterQueue, $ppn);
}


##################################################
# handle running jobs
##################################################

sub checkRunningJobs {

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');

    mkpath("$controlDir/runningJobs");
    opendir(DIR, "$controlDir/runningJobs") || die "Can't open runningJobs/ directory '$controlDir/runningJobs'\n";
    my @runningJobs = readdir(DIR);
    closedir(DIR);

    my $doneJobs;
    my $failedJobs;
    foreach my $runningJob (@runningJobs) {
	next if $runningJob =~ /^\./;
	my $clusterRunningDir = "$clusterServerDir/$runningJob";
	my $clusterJobDir = "$clusterRunningDir/$runningJob";
	if (!clusterTaskRunning($clusterJobDir, $clusterUserName, $clusterServer)) {
	    my $logFile = "$clusterJobDir/$runningJob.log";
	    my $done = $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"if [ -a $logFile ]; then tail -1 $logFile; fi\"'");
	    if ($done && $done =~ /Done/) {
		push(@$doneJobs, $runningJob);
	    } else {
		push(@$failedJobs, $runningJob);
	    }
	}
    }

    return ($doneJobs, $failedJobs);
}

sub clusterTaskRunning {
    my ($clusterJobDir, $clusterUserName, $clusterServer) = @_;

    my $processId = `ssh -2 $clusterUserName\@$clusterServer 'if [ -a $clusterJobDir/processId ];then cat $clusterJobDir/processId; fi'`;

    chomp $processId;

    my $status = 0;
    if ($processId) {
      system("ssh -2 $clusterUserName\@$clusterServer 'ps -p $processId > /dev/null'");
      $status = $? >> 8;
      $status = !$status;
    }
    return $status;
}


##################################################
# handle completed jobs
##################################################
sub handleCompletedJobs {
    my ($doneJobs) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $groupsFile = $mgr->getConfig('groupsFile');
    my $localRunningDir = "$controlDir/runningJobs";

    foreach my $doneJob (@$doneJobs) {
        # copy result from cluster
	my $clusterRunningDir = "$clusterServerDir/$doneJob";
	$mgr->getCluster()->copyFrom("$clusterRunningDir/$doneJob", 'master', "$localRunningDir/$doneJob"); 

        # map to groups
	$mgr->runCmd(0, "orthomclMapProteomeToGroups $localRunningDir/$doneJob/master/blastSimilarity.out $groupsFile >> $localRunningDir/$doneJob/result");

        # zip result
	$mgr->runCmd(0, "zip $localRunningDir/$doneJob/result.zip $localRunningDir/$doneJob/result");
	$mgr->runCmd(0, "rm $localRunningDir/$doneJob/result");

	# email result

        # clean up cluster dir
	my $done = $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"rm -rf $clusterRunningDir/$doneJob\"'");

	# clean up local dir
	remove("$localRunningDir/$doneJob");
    }
}

##################################################
# handle failed jobs
##################################################
sub handleFailedJobs {
    my ($failedJobs) = @_;
}

sub usage {
  print STDERR "

usage:
   orthomclManageUserProteomeJob config_file

** config file **
controlDir=           (local dir to control this job)
clusterUserName=      (login to use to get into cluster server)
clusterServer=        (name of machine)
clusterServerDir=     (dir there to put our stuff in)
clusterQueue=         (queue to use)
numNodes=             (num of nodes to request)
slotsPerNode=         (slots per each node)
ppn=                  (parallelization)
nodePath=             (???)
nodeClass=            (perl class to represent this type of node)
taskSize=             (number of seqs to process in one batch)
taskClass=            (perl class to manage that processing)
subjectFile=          (blast database file)
blastArgs=            (arguments for blast)
blastBinDir=          (location of blast executable)
groupsFile=           (orthomcl groups to map blast results to)
";

exit(1);

}


