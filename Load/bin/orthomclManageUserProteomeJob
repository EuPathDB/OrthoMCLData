#!/usr/bin/perl

use lib "$ENV{GUS_HOME}/lib/perl";
use File::Path;
use File::Copy;
use GUS::Workflow::SshCluster;
use OrthoMCLData::Load::ProteomeJobMgr;
use strict;

=pod 

probe the state of orthomcl user's proteome analysis jobs

should be called by cron once every few minutes

** local dir structure **
controlDir/
  newJobs/
    92hty2k/
      info.txt
      proteome.fasta
  phase1/
    runningJobs/
      i83j89/
        info.txt
        input/
          controller.prop
          task.prop
        proteome.fasta
    doneJobs/
      43k8sl0/
        blastSimilarity.out
        info.txt
        input/
          controller.prop
          task.prop
        proteome.fasta
    failedJobs/
      a7bbe32/                (copied from runningJobs/)
  phase2/                     (same as phase1)


** cluster dir structure **
orthomclUserProteomeJobs/
  phase1/
    runningJobs/
      i83j89/
        info.txt
        input/
          controller.prop
          task.prop
        master/
          completedSubtasks.log
          failures/
          mainresult/
          running/
        i83j89.log
        processId
        proteome.fasta
    failedJobs/
      i83j89/        (copied from runningJobs/)
      i83j89.log     (copied from runningJobs/)
  phase2/            (same as phase1)


** info.txt file **
email=
fastaFileName=
submitTime=

=cut

usage() unless scalar(@ARGV) == 1;

my $configFile = $ARGV[0];

my $controlDir;
my $clusterServerDir;

my $mgr = OrthoMCLData::Load::ProteomeJobMgr->new($configFile);

eval {
    $controlDir = $mgr->getConfig('controlDir');
    $clusterServerDir = $mgr->getConfig('clusterServerDir');

    # phase 1 (self-self blast of user proteome)
    my ($doneJobs, $failedJobs) = checkRunningJobs('phase1');

    handleDoneJobs($doneJobs, 'phase1');

    handleFailedJobs($failedJobs, 'phase1');

    handleNewJobs("$controlDir/newJobs",
		  "$controlDir/phase1/runningJobs",
		  "$clusterServerDir/phase1/runningJobs",
		  'phase1');

    # phase 2 (blast of user proteome against orthomcl proteins)

    my ($doneJobs, $failedJobs) = checkRunningJobs('phase2');

    handleDoneJobs($doneJobs, 'phase2');

    handleFailedJobs($failedJobs, 'phase2');

    handleNewJobs("$controlDir/phase1/doneJobs",
		  "$controlDir/phase2/runningJobs",
		  "$clusterServerDir/phase2/runningJobs",
		  'phase2');


};

$mgr->error("error: '$@'") if $@;


##################################################
# handle running jobs
##################################################

sub checkRunningJobs {
    my ($phase) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');

    my $runningJobsDir = "$controlDir/$phase/runningJobs";
    mkpath($runningJobsDir);
    opendir(DIR, $runningJobsDir) || die "Can't open $phase runningJobs/ directory '$runningJobsDir'\n";
    my @runningJobs = readdir(DIR);
    closedir(DIR);

    my $doneJobs;
    my $failedJobs;
    foreach my $runningJob (@runningJobs) {
	next if $runningJob =~ /^\./;
	print STDERR "checking for done: $runningJob\n";
	my $clusterRunningJobDir = "$clusterServerDir/$phase/runningJobs/$runningJob";
	if (!clusterTaskRunning($clusterRunningJobDir, $clusterUserName, $clusterServer)) {
	  $mgr->log("Found $phase job that has finished running: $runningJob");
	  my $logFile = "$clusterRunningJobDir/$runningJob.log";
	  my $done = $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"if [ -a $logFile ]; then tail -1 $logFile; fi\"'");
	  if ($done && $done =~ /Done/) {
	    push(@$doneJobs, $runningJob);
	  } else {
	    push(@$failedJobs, $runningJob);
	  }
	}
      }

    return ($doneJobs, $failedJobs);
}

sub clusterTaskRunning {
    my ($clusterJobDir, $clusterUserName, $clusterServer) = @_;

    my $processId = `ssh -2 $clusterUserName\@$clusterServer 'if [ -a $clusterJobDir/processId ];then cat $clusterJobDir/processId; fi'`;

    chomp $processId;

    my $status = 0;
    if ($processId) {
      system("ssh -2 $clusterUserName\@$clusterServer 'ps -p $processId > /dev/null'");
      $status = $? >> 8;
      $status = !$status;
    }
    return $status;
}


##################################################
# handle completed jobs
##################################################
sub handleDoneJobs {
    my ($doneJobs, $phase) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $localRunningDir = "$controlDir/$phase/runningJobs";
    my $localDoneDir = "$controlDir/$phase/doneJobs";

    foreach my $doneJob (@$doneJobs) {

      $mgr->log("Handling done $phase job: $doneJob");
      mkpath($localDoneDir);
      move("$localRunningDir/$doneJob", "$localDoneDir/$doneJob");

      # zip blast result
      $mgr->log("  gzipping blast result on cluster");
      my $clusterRunningJobDir = "$clusterServerDir/$phase/runningJobs/$doneJob";
      $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"gzip $clusterRunningJobDir/master/mainresult/blastSimilarity.out\"'");

      # copy result from cluster
      $mgr->log("  copying from cluster");
      $mgr->getCluster()->copyFrom("$clusterRunningJobDir/master/mainresult", 'blastSimilarity.out.gz', "$localDoneDir/$doneJob");
      move("$localDoneDir/$doneJob/blastSimilarity.out.gz", "$localDoneDir/$doneJob/${phase}BlastSimilarity.out.gz");


      # clean up cluster dir
      $mgr->log("  cleaning up cluster job dir");
      $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"rm -rf $clusterRunningJobDir\"'");

      if ($phase eq 'phase2') { 
	  deliverResult("$localDoneDir/$doneJob");

	  $mgr->log("  cleaning up local phase2 job dir");
	  #remove("$localRunningDir/$doneJob");
      }
    }
}

sub deliverResult {
    my ($donePhase2JobDir) = @_;

    my $groupsFile = $mgr->getConfig('groupsFile');

    # map to groups
    $mgr->log("  mapping to groups");
    $mgr->runCmd(0, "orthomclMapProteomeToGroups $donePhase2JobDir/phase1BlastSimilarity.out $donePhase2JobDir/phase2BlastSimilarity.out $groupsFile >> $donePhase2JobDir/result");

    # zip result
    $mgr->log("  zipping");
    $mgr->runCmd(0, "zip $donePhase2JobDir/result.zip $donePhase2JobDir/result");
    $mgr->runCmd(0, "rm $donePhase2JobDir/result");

    # email result
}


##################################################
# handle new jobs
##################################################
sub handleNewJobs {
    my ($newJobsDir, $localRunningDir, $clusterRunningDir, $phase) = @_;

    # find all subdirs 
    opendir(DIR, $newJobsDir) || die "Can't open $phase new jobs directory '$newJobsDir'\n";
    my @newJobs = readdir(DIR);
    closedir(DIR);

    foreach my $newJob (@newJobs) {
	next if $newJob =~ /^\./;
	$mgr->log("New job: $newJob");

	my $clusterUserName = $mgr->getConfig('clusterUserName');
	my $clusterServer = $mgr->getConfig('clusterServer');
	my $newJobDir = "$newJobsDir/$newJob";
	my $runningJobDir = "$localRunningDir/$newJob";
	my $localInputDir = "$runningJobDir/input";
	my $masterDir = "$runningJobDir/master";
	my $clusterRunningJobDir = "$clusterRunningDir/$newJob";
	my $clusterInputDir = "$clusterRunningJobDir/input";

	if ($phase eq 'phase1') {
	    validateProteomeFile("$newJobDir/proteome.fasta");
	}

        # move new job dir to running/
	mkpath($runningJobDir);
	move("$newJobsDir/$newJob", $runningJobDir);

	# move proteome file to localInputDir
	mkpath($localInputDir);
	#$move("$runningJobDir/proteome.fasta", $localInputDir);

	my $dbFilePath =  ($phase eq 'phase1')?
	  "$clusterRunningJobDir/proteome.fasta" :
	    $mgr->getConfig('dbFilePath');

	# build input/ dir
	makeTaskFile($localInputDir, $clusterInputDir, $clusterRunningJobDir, $dbFilePath);
	makeControllerFile($localInputDir, $clusterInputDir);

	# mirror job to cluster
	$mgr->log("Mirroring $newJob/ to cluster");
	$mgr->getCluster()->copyTo($localRunningDir, $newJob, $clusterRunningDir);

	if ($phase eq 'phase1') {
	    # format db
	    my $blastBinDir = $mgr->getConfig('blastBinDir');
	    my $cmd = "$blastBinDir/formatdb -i $dbFilePath -p T";
	    $mgr->log("formatting proteome.fasta for self-self blast");
	    $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"$cmd\"'");
	}

	# start cluster job
	startJob("$clusterRunningJobDir", $newJob);
    }

}

sub validateProteomeFile {
    my ($proteomeFile) = @_;
}

sub makeTaskFile {
    my ($localInputDir, $clusterInputDir, $clusterRunningJobDir, $dbFilePath) = @_;
      open(F, ">$localInputDir/task.prop") || die "Can't open task prop file '$localInputDir/task.prop' for writing";

    my $blastBinDir = $mgr->getConfig('blastBinDir');
    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $dbFilePath = $mgr->getConfig('dbFilePath');

    print F
"blastBinDir=$blastBinDir
dbFilePath=$dbFilePath
inputFilePath=$clusterRunningJobDir/proteome.fasta
dbType=p
regex='(\\S+)'
blastProgram=blastp
blastParamsFile=blastParams
blastVendor=ncbi
";
    close(F);

    # discover size of blast db (ie, count of orthomcl proteins)
    my $dbSize = $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"grep \\> $dbFilePath |wc -l\"'");

    # make blastParams file
    my $blastArgs = $mgr->getConfig('blastArgs');
    die "error: do not include -z arg in blastArgs property.  it is discovered dynamically" if $blastArgs =~ /z/;
    open(F, ">$localInputDir/blastParams") || die "Can't open blast params file '$localInputDir/blastParams' for writing";;
    print F "$blastArgs -z $dbSize\n";
    close(F);
}

sub makeControllerFile {
    my ($localInputDir, $clusterInputDir) = @_;
  my ($self, $taskInputDir, $slotsPerNode, $taskSize, $taskClass) = @_;

  my $nodePath = $mgr->getConfig('nodePath');
  my $slotsPerNode = $mgr->getConfig('slotsPerNode');
  my $nodeClass = $mgr->getConfig('nodeClass');
  my $taskSize = $mgr->getConfig('taskSize');
  my $taskClass = $mgr->getConfig('taskClass');
  my $nodeClass = $mgr->getConfig('nodeClass');

  my $clusterMasterDir = $clusterInputDir;
  $clusterMasterDir =~ s/input/master/;
  $nodeClass = 'DJob::DistribJob::BprocNode' unless $nodeClass;

  # print out the file
  my $controllerPropFile = "$localInputDir/controller.prop";
  open(F, ">$controllerPropFile")
      || $self->error("Can't open controller prop file '$controllerPropFile' for writing");
  print F 
"masterdir=$clusterMasterDir
inputdir=$clusterInputDir
nodedir=$nodePath
slotspernode=$slotsPerNode
subtasksize=$taskSize
taskclass=$taskClass
nodeclass=$nodeClass
restart=no
";
    close(F);
}

sub startJob {
    my ($clusterJobDir, $jobName) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $numNodes = $mgr->getConfig('numNodes');
    my $clusterQueue = $mgr->getConfig('clusterQueue');
    my $ppn = $mgr->getConfig('ppn');

    $mgr->log("Starting job on cluster in $clusterJobDir");
    $mgr->runClusterTask($clusterUserName, $clusterServer, "$clusterJobDir/processId", "$clusterJobDir/$jobName.log", "$clusterJobDir/input/controller.prop", $numNodes, 14400, $clusterQueue, $ppn);
}


##################################################
# handle failed jobs
##################################################
sub handleFailedJobs {
    my ($failedJobs, $phase) = @_;

    my $clusterUserName = $mgr->getConfig('clusterUserName');
    my $clusterServer = $mgr->getConfig('clusterServer');
    my $localRunningDir = "$controlDir/$phase/runningJobs";
    my $localFailedDir = "$controlDir/$phase/failedJobs";

    foreach my $failedJob (@$failedJobs) {

      $mgr->log("Handling $phase failed job: $failedJob");
      mkpath("$localRunningDir/$failedJob");
      move("$localRunningDir/$failedJob", "$localFailedDir/$failedJob");

      # clean up cluster dir
      $mgr->log("  moving cluster job to failed dir");
      my $clusterRunningJobDir = "$clusterServerDir/$phase/runningJobs/$failedJob";
      $mgr->runCmd(0, "ssh -2 $clusterUserName\@$clusterServer '/bin/bash -login -c \"mv $clusterRunningJobDir $clusterServerDir/$phase/failedJobs\"'");
    }
}

sub usage {
  print STDERR "

usage:
   orthomclManageUserProteomeJob config_file

** config file **
controlDir=           (local dir to control this job)
clusterUserName=      (login to use to get into cluster server)
clusterServer=        (name of machine)
clusterServerDir=     (dir there to put our stuff in)
clusterQueue=         (queue to use)
numNodes=             (num of nodes to request)
slotsPerNode=         (slots per each node)
ppn=                  (parallelization)
nodePath=             (???)
nodeClass=            (perl class to represent this type of node)
taskSize=             (number of seqs to process in one batch)
taskClass=            (perl class to manage that processing)
orthomclProteinsFile= (blast database file)
blastArgs=            (arguments for blast)
blastBinDir=          (location of blast executable)
groupsFile=           (orthomcl groups to map blast results to)
";

exit(1);

}


